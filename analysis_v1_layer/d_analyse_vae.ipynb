{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphomics.io.io import load_obj, save_obj\n",
    "from kxa_analysis import dimreduction_runner, bootstrap_runner\n",
    "import numpy as np\n",
    "from kxa_analysis import plot_2d, plot_pi, plot_dist_matrix, mask_pi, get_base, inverse_function, get_2d, plot_vae_dist\n",
    "import plotly.express as px\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import torch as th\n",
    "from morphomics.nn_models import train_test\n",
    "\n",
    "import pandas as pd\n",
    "base_path = \"results/vae_analysis/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path for storing results\n",
    "dimreducer_path = \"results/dim_reduction/Morphomics.PID_v1_l.pi_pca_vae_1_fitted_dimreducer\"\n",
    "reduced_path = \"results/dim_reduction/Morphomics.PID_v1_l.pi_pca_vae_1_reduced_data\"\n",
    "\n",
    "vae_pip = load_obj(dimreducer_path)\n",
    "mf = load_obj(reduced_path)\n",
    "mf = mf.reset_index()  # Resets the index and adds the old index as a column\n",
    "mf.rename(columns={'index': 'old_idcs'}, inplace=True)\n",
    "pis = mf['pi']\n",
    "pi_example = pis.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base(pi, pixes_tokeep):\n",
    "    pi_full = np.zeros_like(pi_example)\n",
    "    pi_full[pixes_tokeep] = pi\n",
    "    return pi_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for the condition (Model + Sex)\n",
    "mf['Condition'] = mf['Model'] + \"-\" + mf['Sex']\n",
    "# Sort by condition\n",
    "mf_sorted = mf.sort_values(by='Condition').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixes_tokeep = vae_pip['pixes_tokeep']\n",
    "pis_threshold = pis.apply(lambda pi: mask_pi(pi, pixes_tokeep)[0])\n",
    "pis_filtered = pis.apply(lambda pi: mask_pi(pi, pixes_tokeep)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardizer = vae_pip['standardizer']\n",
    "pis_filtered_arr = np.vstack(pis_filtered)\n",
    "pis_scaled = standardizer.transform(pis_filtered_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = vae_pip['fitted_pca_vae'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pis_pca = pca.transform(pis_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = vae_pip['fitted_pca_vae'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pis_pca_torch = th.tensor(pis_pca, dtype=th.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, z_mean, z_log_var, mse = train_test.vae_test(data = pis_pca_torch,\n",
    "                                                model = vae, \n",
    "                                                sample_size = 3,\n",
    "                                               )\n",
    "print('mse:', mse)\n",
    "print('sample size:', z_mean.shape)\n",
    "print('pred shape:', pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "come back to pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_processed_pi_mean = pred.mean(dim=0)\n",
    "mf['pred'] = list(pred_processed_pi_mean)\n",
    "pred_processed_pi = pred_processed_pi_mean.cpu().detach().numpy()  # If it's a PyTorch tensor, convert it to NumPy\n",
    "pred_scaled_pi = pca.inverse_transform(pred_processed_pi)\n",
    "pred_filter_pi = standardizer.inverse_transform(pred_scaled_pi)\n",
    "mf['pi_filter_pred'] = list(pred_filter_pi)\n",
    "mf['pi_pred'] = mf['pi_filter_pred'].apply(lambda pi: get_base(pi, pixes_tokeep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_points = 5 # Number of points along the line\n",
    "x_values = np.linspace(-1, 1, nb_points)  # X values from -0.5 to 1\n",
    "y_values = (-1/3) * x_values - (1/6)  # Apply the line equation\n",
    "\n",
    "interpolation = np.column_stack((x_values, y_values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_interpolation = pd.DataFrame()\n",
    "mf_vae_kxa =  mf[mf['Model'].isin(['1xSaline_4h', '1xKXA_4h'])].copy()\n",
    "mf_interpolation['Condition'] = mf_vae_kxa['Condition']\n",
    "mf_interpolation['pca_vae'] = mf_vae_kxa['pca_vae']\n",
    "\n",
    "\n",
    "# Add interpolation lines \n",
    "mf_interpolation_ = pd.DataFrame(data=nb_points*['interpolation'], columns = ['Condition'])\n",
    "mf_interpolation_['pca_vae'] = list(interpolation)\n",
    "mf_inter = pd.concat((mf_interpolation, mf_interpolation_)).reset_index(drop=True)\n",
    "# Add color for interpolation \n",
    "from kxa_analysis import merged_dict\n",
    "color_dict = dict(merged_dict, **{'interpolation': 'rgb(128, 0, 0)'  # or hex: '#800000'\n",
    "\n",
    " # or hex: '#FFA500'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d(mf_inter,\n",
    "        feature='pca_vae', \n",
    "        title = 'VAE Latent Space of Persistence Image',\n",
    "        conditions = ['Condition'],\n",
    "        colors= color_dict,\n",
    "        extension = 'html',\n",
    "            ax_labels = ['Dim 1', 'Dim 2'],\n",
    "                    name = f\"{base_path}/pi_vae_kxa_interpolation_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pi_list = []\n",
    "pred_pi_scaled_list = []\n",
    "for pt in interpolation:\n",
    "    pred_pi, pi_scaled = inverse_function(pt, model = vae, pca = pca, scaler = standardizer, filter=pixes_tokeep)\n",
    "    pred_pi = get_2d(pred_pi)\n",
    "    pred_pi_list.append(pred_pi)\n",
    "\n",
    "    pi_scaled = get_2d(pi_scaled)\n",
    "    pred_pi_scaled_list.append(pi_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "\n",
    "# Set the base path and save name\n",
    "base_path = \"results/vae_analysis\"\n",
    "save_name = f\"{base_path}/reconstructed_pi_scaled_interpolation_\"\n",
    "\n",
    "# Assuming pred_pi_scaled_list and interpolation are already defined\n",
    "# Convert the predicted persistence images to a NumPy array if they aren't already\n",
    "pred_pi_scaled_list = np.array(pred_pi_scaled_list)\n",
    "num_images = pred_pi_scaled_list.shape[0]\n",
    "\n",
    "# Calculate the number of rows needed for a 2-column layout (round up for odd numbers)\n",
    "num_rows = (num_images + 1) // 2\n",
    "\n",
    "# Create a figure with subplots; adjust the figsize for better visibility\n",
    "fig, ax = plt.subplots(num_rows, 2, figsize=(12, num_rows * 5))\n",
    "\n",
    "# Define vmin and vmax for normalization\n",
    "vmin, vmax = pred_pi_scaled_list.min(), pred_pi_scaled_list.max()\n",
    "\n",
    "# Custom colormap: Define colors for negative, zero, and positive values\n",
    "colors_list = [\"purple\", \"white\", \"orange\"]\n",
    "custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap\", colors_list)\n",
    "\n",
    "# Normalize the colormap such that 0 is centered\n",
    "norm = mcolors.TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax)\n",
    "\n",
    "# Loop through each image and plot the heatmap\n",
    "for i in range(num_rows):\n",
    "    for j in range(2):\n",
    "        index = i * 2 + j  # Compute the index for the flattened matrix\n",
    "        if index < num_images:\n",
    "            im = ax[i, j].imshow(\n",
    "                pred_pi_scaled_list[index],\n",
    "                cmap=custom_cmap,\n",
    "                norm=norm,\n",
    "                interpolation='nearest',\n",
    "                origin='lower'\n",
    "            )\n",
    "            ax[i, j].set_title(f'Reconstructed Scaled Persistence Image {index + 1} ({np.round(interpolation[index], 2)})')\n",
    "        else:\n",
    "            ax[i, j].axis('off')  # Turn off axis for empty subplots\n",
    "\n",
    "# Create a single colorbar spanning all subplots using the last image's mappable\n",
    "cbar = fig.colorbar(im, ax=ax, orientation='vertical', fraction=0.03, pad=0.04)\n",
    "cbar.set_label('Scaled Persistence Density')\n",
    "\n",
    "# Adjust layout to avoid overlap and reserve space for the colorbar\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.85)\n",
    "\n",
    "# Save the figure as a PDF\n",
    "fig.savefig(save_name + '.pdf', format='pdf')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = f\"{base_path}/reconstructed_pi_interpolation_\"\n",
    "\n",
    "# Assuming pred_pi_list and interpolation are already defined\n",
    "pred_pi_list = np.array(pred_pi_list)\n",
    "num_images = pred_pi_list.shape[0]\n",
    "\n",
    "# Calculate the number of rows needed for 2x2 plots\n",
    "num_rows = (num_images + 1) // 2  # Round up for odd numbers\n",
    "\n",
    "# Create a figure for the plots\n",
    "fig, ax = plt.subplots(num_rows, 2, figsize=(12, num_rows * 5))  # Adjusting figsize for better visibility\n",
    "\n",
    "# Define vmin and vmax for normalization\n",
    "vmin = np.min(pred_pi_list)\n",
    "vmax = np.max(pred_pi_list)\n",
    "\n",
    "for i in range(num_rows):\n",
    "    for j in range(2):\n",
    "        index = i * 2 + j  # Compute the index for the flattened matrix\n",
    "        if index < num_images:\n",
    "            # Plot the predicted heatmap with the inverted hot colormap\n",
    "            cax = ax[i, j].imshow(pred_pi_list[index], cmap='hot', vmin=vmin, vmax=vmax, interpolation='nearest', origin='lower')\n",
    "            ax[i, j].set_title(f'Reconstructed Persistence Image {index + 1} {np.round(interpolation[index], 2)}')\n",
    "        else:\n",
    "            ax[i, j].axis('off')  # Turn off the axis for blank spaces\n",
    "\n",
    "# Create a single colorbar that spans all heatmaps\n",
    "# Use the first heatmap's axes to set the colorbar\n",
    "cbar = fig.colorbar(cax, ax=ax[:, :], orientation='vertical', fraction=0.03, pad=0.04)\n",
    "cbar.set_label('Persistence Density')  # Optional: Add a label to the colorbar\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.85)  # Adjust the right side to give space for the colorbar\n",
    "\n",
    "# Save the figure as a PDF with the specified name\n",
    "fig.savefig(save_name + '.pdf', format='pdf')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming pred_pi_list is your list of 2D arrays\n",
    "# Assuming interpolation is the list of coordinates (same length as pred_pi_list)\n",
    "# Example: interpolation = [np.random.rand(2), np.random.rand(2), ...]\n",
    "\n",
    "# Step 1: Compute the sum and max for each 2D array in the list\n",
    "sum_values = []\n",
    "max_values = []\n",
    "coordinates = []\n",
    "\n",
    "for i, pred_pi in enumerate(pred_pi_list):\n",
    "    sum_values.append(np.sum(pred_pi))  # Sum of all pixel values in the array\n",
    "    max_values.append(np.max(pred_pi))  # Max pixel value in the array\n",
    "    coordinates.append(np.round(interpolation[i], 2))  # Round coordinates to 2 decimals\n",
    "\n",
    "# Step 2: Create a DataFrame to store the results\n",
    "data = {'Index': np.arange(1, len(pred_pi_list) + 1),\n",
    "        'Sum': [np.round(val, 2) for val in sum_values],  # Round sum values to 2 decimals\n",
    "        'Max Value': [f\"{val:.2e}\" if val != 0 else \"0.00\" for val in max_values],  # Scientific notation for Max Value\n",
    "        'Coordinates': coordinates}  # Add coordinates column\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 3: Plot the table using matplotlib\n",
    "fig, ax = plt.subplots(figsize=(10, 4))  # Adjust the figure size\n",
    "ax.axis('off')  # Turn off the axes\n",
    "\n",
    "# Add the title\n",
    "plt.title('Reconstructed Persistence Density Statistics from Interpolation', fontsize=16, ha='center', pad=20)\n",
    "\n",
    "# Create a table with the DataFrame values\n",
    "table = ax.table(cellText=df.values, colLabels=df.columns, loc='center', cellLoc='center')\n",
    "\n",
    "# Optionally, adjust the font size or other styles\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.2, 1.2)\n",
    "\n",
    "# Optionally, you can save the table as a PDF\n",
    "# fig.savefig('table_output.pdf', format='pdf')\n",
    "\n",
    "# Display the plot with the table\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Assuming pred_pi_list contains 2D arrays (e.g., size 100x100)\n",
    "# and interpolation is a list of coordinate arrays (one for each image)\n",
    "# For example:\n",
    "# pred_pi_list = [np.random.rand(100, 100) for _ in range(5)]\n",
    "# interpolation = [np.random.rand(2) for _ in range(5)]\n",
    "# base_path is your directory for saving\n",
    "\n",
    "# Step 1: Initialize a list to store the projection vectors\n",
    "projection_vectors = []\n",
    "\n",
    "# Step 2: Loop through each 2D array in the list\n",
    "for pred_pi, coord in zip(pred_pi_list, interpolation):\n",
    "    # Step 3: Extract the diagonal values (projection on the diagonal)\n",
    "    diagonal_projection = np.diagonal(pred_pi)[:70]  # Adjust the slice as needed\n",
    "    # Store the projection vector for this 2D array\n",
    "    projection_vectors.append(diagonal_projection)\n",
    "\n",
    "# Step 4: Convert the list of vectors into a 2D array (if needed for further analysis)\n",
    "projection_vectors = np.array(projection_vectors)\n",
    "\n",
    "# Create a custom colormap that goes from magenta -> cyan -> grey -> black\n",
    "cmap = mcolors.LinearSegmentedColormap.from_list('magenta_cyan_grey_black', \n",
    "                                                        ['magenta', 'purple', 'cyan', 'grey', 'black'])\n",
    "\n",
    "# Create a figure for the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Generate a color scale for the lines\n",
    "num_lines = len(projection_vectors)\n",
    "colors = [cmap(i / num_lines) for i in range(num_lines)]  # Normalize to [0, 1]\n",
    "\n",
    "for i, (projection, color) in enumerate(zip(projection_vectors, colors)):\n",
    "    ax.plot(projection, label=f'{np.round(interpolation[i], 2)}', color=color)\n",
    "    \n",
    "ax.set_xlabel('Persistence Image Diagonal')\n",
    "ax.set_ylabel('Persistence Density')\n",
    "ax.set_title('Diagonal of Reconstructed Persistence Images from Interpolation')\n",
    "ax.legend()\n",
    "\n",
    "# Define save_name using your base_path\n",
    "save_name = f\"{base_path}/reconstructed_pi_diagonal_\"\n",
    "\n",
    "# Save the figure as a PDF\n",
    "fig.savefig(save_name + '.pdf', format='pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Assume pred_pi_list is your list of 2D arrays (each 100x100)\n",
    "# and interpolation is a list of coordinate arrays for labeling.\n",
    "# For example:\n",
    "# pred_pi_list = [np.random.rand(100,100) for _ in range(5)]\n",
    "# interpolation = [np.random.rand(2) for _ in range(5)]\n",
    "# Also assume base_path is defined.\n",
    "\n",
    "# Create a custom colormap that goes from magenta -> cyan -> grey -> black\n",
    "custom_cmap = mcolors.LinearSegmentedColormap.from_list('magenta_cyan_grey_black', \n",
    "                                                        ['magenta', 'purple', 'cyan', 'grey', 'black'])\n",
    "num_images = len(pred_pi_list)\n",
    "# Generate a list of colors from the custom colormap for each image\n",
    "colors = [custom_cmap(i / num_images) for i in range(num_images)]\n",
    "\n",
    "# We'll store the \"thickness\" curves (variance along perpendicular diagonals)\n",
    "thickness_curves = []\n",
    "\n",
    "# Loop over each image\n",
    "for img in pred_pi_list:\n",
    "    n = img.shape[0]  # Should be 100\n",
    "    thickness_variance = []\n",
    "    # For each point along the main diagonal at (i,i), compute the variance of pixel values\n",
    "    # along the perpendicular direction. The perpendicular line has points: (i+d, i-d)\n",
    "    for i in range(n):\n",
    "        d_max = min(i, n - 1 - i)  # Maximum offset d so indices remain within bounds\n",
    "        # Collect pixel values along the perpendicular line through (i, i)\n",
    "        values = [img[i + d, i - d] for d in range(-d_max, d_max + 1) ]\n",
    "        # Compute variance as a measure of the \"thickness\" at that diagonal position\n",
    "        thickness_variance.append(np.sum(values))\n",
    "    thickness_curves.append(np.array(thickness_variance)[:70])\n",
    "\n",
    "# Create a figure for the thickness curves plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot the thickness curves for each image\n",
    "for i in range(num_images):\n",
    "    label_str = f\"Image {i+1} {np.round(interpolation[i], 2)}\"\n",
    "    ax.plot(thickness_curves[i], label=label_str, color=colors[i], linewidth=2)\n",
    "    \n",
    "ax.set_xlabel(\"Diagonal Index\")\n",
    "ax.set_ylabel(\"Thickness\")\n",
    "ax.set_title(\"Local Thickness Along the Diagonals\")\n",
    "ax.legend()\n",
    "\n",
    "# Define the save name using base_path and a descriptive filename for thickness curves\n",
    "save_name = f\"{base_path}/reconstructed_pi_thickness_\"\n",
    "\n",
    "# Save the figure as a PDF\n",
    "fig.savefig(save_name + '.pdf', format='pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Space Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_origin = np.array([0,0])\n",
    "pi_origin = inverse_function(point_origin, model = vae, pca = pca, scaler = standardizer, filter=pixes_tokeep)\n",
    "pi_origin_2d = get_2d(pi_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pi(pi_origin_2d, cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.loc[:, 'dist_2d'] = mf['pca_vae'].apply(lambda p: np.linalg.norm(p - point_origin))\n",
    "mf.loc[:, 'dist_pi_pred'] = mf['pi_pred'].apply(lambda p: np.linalg.norm(p - pi_origin))\n",
    "mf.loc[:, 'dist_pi'] = mf['pi'].apply(lambda p: np.linalg.norm(p - pi_origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vae_dist(mf, points = 'pca_vae', dist='dist_pi_pred', vmin=0.0, vmax=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vae_dist(mf, points = 'pca_vae', dist='dist_pi', vmin=0.0, vmax=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.loc[:, 'mse'] = mf.apply(lambda row: np.linalg.norm(row['pi_pred'] - row['pi']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vae_dist(mf, points = 'pca_vae', dist='mse', vmin=0.0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kxa-ana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
